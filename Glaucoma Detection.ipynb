{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "KV61O5UtyawW",
        "wG9gByWYwti1",
        "FLz1hd6OpOB_",
        "SWHfopJbNL_8",
        "csted7p5Xfuw",
        "DKpZUcq-4C6o"
      ],
      "mount_file_id": "1uYM_0tZ1-OmseUWbAmm3t6FRPsdpUpAP",
      "authorship_tag": "ABX9TyOhiDDssZxGAKpbNHf+CSeI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fadiahanifa/Glaucoma-UNet/blob/main/Glaucoma%20Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Glaucoma Detection based on quantification of optic disc and optic cup**\n",
        "Glaucoma is eye disease which is caused by increase of intraocular pressure. The pressure is damaging optic nerve head and could lead to partially or even entirely loss of eyesight if there is no appropriate treatment. In Indonesia, only 51.4% of glaucoma cases were only examined after they were at the severe stage of glaucoma namely when there is already significant damage to the eye or even when vision has been greatly reduced. Therefore, early glaucoma detection is crucial so that glaucoma can be treated as fast as possible. Currently, there are many developments in this field that have been carried out using various types of approaches. One of the approaches is by quantification of optic disc and cupâ€™s such as cup to disc ratio. In this approach, we carried out the classification using a four step algorithm.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7CV7UhoaxLW8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prerequisites"
      ],
      "metadata": {
        "id": "KV61O5UtyawW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swQtkIeCflkr",
        "outputId": "4b631276-d534-4c40-8257-1364cf5c27e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.9/dist-packages (4.4.0)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.6.4-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.9/dist-packages (from gdown) (2.25.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from gdown) (3.9.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (1.26.14)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.4.0\n",
            "    Uninstalling gdown-4.4.0:\n",
            "      Successfully uninstalled gdown-4.4.0\n",
            "Successfully installed gdown-4.6.4\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1MI5jnTSwtJcmaUUa_0qekktw0w-LHuFA\n",
            "To: /content/Glaucoma Detection.zip\n",
            "100% 151M/151M [00:08<00:00, 17.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --no-cache-dir gdown\n",
        "!gdown 1MI5jnTSwtJcmaUUa_0qekktw0w-LHuFA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -u \"/content/Glaucoma Detection.zip\""
      ],
      "metadata": {
        "id": "8QzorQi2jg9E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d64473e-13c9-4198-cc24-51cd50547ca2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/Glaucoma Detection.zip\n",
            "   creating: Glaucoma Detection/\n",
            "  inflating: Glaucoma Detection/.DS_Store  \n",
            "  inflating: __MACOSX/Glaucoma Detection/._.DS_Store  \n",
            "   creating: Glaucoma Detection/Sample Images/\n",
            "   creating: Glaucoma Detection/Models and Templates/\n",
            "  inflating: __MACOSX/Glaucoma Detection/._Models and Templates  \n",
            "  inflating: Glaucoma Detection/Sample Images/drishtiGS_092.png  \n",
            "  inflating: __MACOSX/Glaucoma Detection/Sample Images/._drishtiGS_092.png  \n",
            "  inflating: Glaucoma Detection/Sample Images/n0317.jpg  \n",
            "  inflating: __MACOSX/Glaucoma Detection/Sample Images/._n0317.jpg  \n",
            "  inflating: Glaucoma Detection/Sample Images/drishtiGS_010.png  \n",
            "  inflating: __MACOSX/Glaucoma Detection/Sample Images/._drishtiGS_010.png  \n",
            "  inflating: Glaucoma Detection/Sample Images/n0294.jpg  \n",
            "  inflating: __MACOSX/Glaucoma Detection/Sample Images/._n0294.jpg  \n",
            "   creating: Glaucoma Detection/Models and Templates/model OD final/\n",
            "  inflating: __MACOSX/Glaucoma Detection/Models and Templates/._model OD final  \n",
            "   creating: Glaucoma Detection/Models and Templates/model OC final/\n",
            "  inflating: __MACOSX/Glaucoma Detection/Models and Templates/._model OC final  \n",
            "  inflating: Glaucoma Detection/Models and Templates/ROItemplateBlue.png  \n",
            "  inflating: __MACOSX/Glaucoma Detection/Models and Templates/._ROItemplateBlue.png  \n",
            "  inflating: Glaucoma Detection/Models and Templates/ROItemplateRed.png  \n",
            "  inflating: __MACOSX/Glaucoma Detection/Models and Templates/._ROItemplateRed.png  \n",
            "  inflating: Glaucoma Detection/Models and Templates/model2a_axes.sav  \n",
            "  inflating: __MACOSX/Glaucoma Detection/Models and Templates/._model2a_axes.sav  \n",
            "  inflating: Glaucoma Detection/Models and Templates/ROItemplateGreen.png  \n",
            "  inflating: __MACOSX/Glaucoma Detection/Models and Templates/._ROItemplateGreen.png  \n",
            "  inflating: Glaucoma Detection/Models and Templates/model OD final/keras_metadata.pb  \n",
            "  inflating: __MACOSX/Glaucoma Detection/Models and Templates/model OD final/._keras_metadata.pb  \n",
            "   creating: Glaucoma Detection/Models and Templates/model OD final/variables/\n",
            "  inflating: __MACOSX/Glaucoma Detection/Models and Templates/model OD final/._variables  \n",
            "  inflating: Glaucoma Detection/Models and Templates/model OD final/saved_model.pb  \n",
            "  inflating: __MACOSX/Glaucoma Detection/Models and Templates/model OD final/._saved_model.pb  \n",
            "   creating: Glaucoma Detection/Models and Templates/model OD final/assets/\n",
            "  inflating: __MACOSX/Glaucoma Detection/Models and Templates/model OD final/._assets  \n",
            "  inflating: Glaucoma Detection/Models and Templates/model OC final/keras_metadata.pb  \n",
            "  inflating: __MACOSX/Glaucoma Detection/Models and Templates/model OC final/._keras_metadata.pb  \n",
            "   creating: Glaucoma Detection/Models and Templates/model OC final/variables/\n",
            "  inflating: __MACOSX/Glaucoma Detection/Models and Templates/model OC final/._variables  \n",
            "  inflating: Glaucoma Detection/Models and Templates/model OC final/saved_model.pb  \n",
            "  inflating: __MACOSX/Glaucoma Detection/Models and Templates/model OC final/._saved_model.pb  \n",
            "   creating: Glaucoma Detection/Models and Templates/model OC final/assets/\n",
            "  inflating: __MACOSX/Glaucoma Detection/Models and Templates/model OC final/._assets  \n",
            "  inflating: Glaucoma Detection/Models and Templates/model OD final/variables/variables.data-00000-of-00001  \n",
            "  inflating: __MACOSX/Glaucoma Detection/Models and Templates/model OD final/variables/._variables.data-00000-of-00001  \n",
            "  inflating: Glaucoma Detection/Models and Templates/model OD final/variables/variables.index  \n",
            "  inflating: __MACOSX/Glaucoma Detection/Models and Templates/model OD final/variables/._variables.index  \n",
            "  inflating: Glaucoma Detection/Models and Templates/model OC final/variables/variables.data-00000-of-00001  \n",
            "  inflating: __MACOSX/Glaucoma Detection/Models and Templates/model OC final/variables/._variables.data-00000-of-00001  \n",
            "  inflating: Glaucoma Detection/Models and Templates/model OC final/variables/variables.index  \n",
            "  inflating: __MACOSX/Glaucoma Detection/Models and Templates/model OC final/variables/._variables.index  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import cv2\n",
        "import math \n",
        "import numpy as np\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "\n",
        "from google.colab import files\n",
        "from keras import backend as K\n",
        "from numpy.lib.twodim_base import diag\n",
        "from skimage.transform import resize\n",
        "from skimage.segmentation import slic"
      ],
      "metadata": {
        "id": "isxvu9fBwNea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Models"
      ],
      "metadata": {
        "id": "tt7LJnWUw4Mp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Localization Templates\n",
        "image_R = cv2.imread('/content/Glaucoma Detection/Models and Templates/ROItemplateRed.png', 0)\n",
        "image_G = cv2.imread('/content/Glaucoma Detection/Models and Templates/ROItemplateGreen.png', 0)\n",
        "image_B = cv2.imread('/content/Glaucoma Detection/Models and Templates/ROItemplateBlue.png', 0)\n",
        "image_templates = [image_R, image_G, image_B]"
      ],
      "metadata": {
        "id": "bLM8bCDlqLk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics\n",
        "def recall_m(y_true, y_pred):\n",
        "    '''\n",
        "    calculate the recall\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    y_true : array of int/float\n",
        "      Ground truth (correct) target values.\n",
        "    y_pred : array of int/float\n",
        "      estimated value returned by a classifier.\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    recall : float\n",
        "    '''\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    '''\n",
        "    calculate the precision\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    y_true : array of int/float\n",
        "      Ground truth (correct) target values.\n",
        "    y_pred : array of int/float\n",
        "      estimated value returned by a classifier.\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    recall : float\n",
        "    '''\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def fscore(y_true, y_pred):\n",
        "    '''\n",
        "    calculate the fscore\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    y_true : array of int/float\n",
        "      Ground truth (correct) target values.\n",
        "    y_pred : array of int/float\n",
        "      estimated value returned by a classifier.\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    fscore : float\n",
        "    '''\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "metadata": {
        "id": "Sg4Y0Ypbs930"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Segmentation Models\n",
        "model_OD = tf.keras.models.load_model('/content/Glaucoma Detection/Models and Templates/model OD final', custom_objects={'fscore':fscore})\n",
        "model_OC = tf.keras.models.load_model('/content/Glaucoma Detection/Models and Templates/model OC final', custom_objects={'fscore':fscore})"
      ],
      "metadata": {
        "id": "MJhM5VKaqUpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Model\n",
        "model2a_axes = pickle.load(open('/content/Glaucoma Detection/Models and Templates/model2a_axes.sav', 'rb'))"
      ],
      "metadata": {
        "id": "Cdf95FwvvojA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions"
      ],
      "metadata": {
        "id": "wG9gByWYwti1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLz1hd6OpOB_"
      },
      "source": [
        "### Localization Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iZFrPdyqCy9"
      },
      "outputs": [],
      "source": [
        "def extract_BR_map(src, mask, numSegments=50, sigma=10):\n",
        "  '''\n",
        "    This is the function of brightness map of retinal images extraction. \n",
        "    Brightness map is an image that contain well-segmented areas of retinal images\n",
        "    that filled with the brightness of those areas. This maps give the brightness\n",
        "    information of all area in retinal image. Since the Optic Disc typically\n",
        "    the one of brightest area in retinal images, this map helps identify the\n",
        "    location of Optic Disc.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    src: array of int\n",
        "      retinal images (RGB)\n",
        "    mask: array of int\n",
        "      mask for Masking out non-retinal area of the image\n",
        "    numSegments: int\n",
        "      The number of segment in the brightness map\n",
        "    sigma: int\n",
        "      the size of gaussian filter for blurring the image\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    combined_map: array of int\n",
        "      the combined brightness across R, G, B channels\n",
        "  '''    \n",
        "\n",
        "  #Resize imagen source\n",
        "  H, W = src.shape[:2]\n",
        "  \n",
        "  # Resizing the image to quarter size for accelerating the computation\n",
        "  resized_src = resize(src, output_shape=(H//4, W//4), mode = 'constant')\n",
        "  resized_mask =  resize(mask, output_shape=(H//4, W//4), mode = 'constant')\n",
        "\n",
        "  # Blurring the image tim improve the segment accuracy\n",
        "  blur = cv2.GaussianBlur(resized_src, (37, 37), 0)\n",
        "\n",
        "  # Segmenting the retinal image using SLIC algorithm \n",
        "  segments = slic(blur, n_segments=numSegments, sigma=sigma, mask=resized_mask)\n",
        "  # boundary = mark_boundaries(resized_src, segments)\n",
        "\n",
        "  labels = np.unique(segments)\n",
        "  h, w = resized_src.shape[:2]\n",
        "\n",
        "  # initiate the brightness map of R, G, and B channel\n",
        "  g_map = np.zeros([h, w], np.float32)\n",
        "  r_map = np.zeros([h, w], np.float32)\n",
        "  b_map = np.zeros([h, w], np.float32)\n",
        "\n",
        "\n",
        "  r_src = resized_src[:, :, 0]\n",
        "  g_src = resized_src[:, :, 1]\n",
        "  b_src = resized_src[:, :, 2]\n",
        "\n",
        "  # Filling the segment with brightness of it\n",
        "  for label in labels:\n",
        "    # Brightness is define as the maximum intensity of each segment\n",
        "    r_map[segments==label] = np.max(r_src[segments==label])\n",
        "    g_map[segments==label] = np.max(g_src[segments==label])\n",
        "    b_map[segments==label] = np.max(b_src[segments==label])\n",
        "\n",
        "  # Resize back the brightness map to its original size\n",
        "  r_resized_map = resize(r_map, output_shape=(H, W), mode='constant', preserve_range=True)\n",
        "  g_resized_map = resize(g_map, output_shape=(H, W), mode='constant', preserve_range=True)\n",
        "  b_resized_map = resize(b_map, output_shape=(H, W), mode='constant', preserve_range=True)\n",
        "\n",
        "  # combining brightness map using average method\n",
        "  combined_map = (r_resized_map + g_resized_map + b_resized_map)/3\n",
        "  \n",
        "  return combined_map"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def padding(NCC, h, w):\n",
        "  '''\n",
        "    This function will zero pad the NCC map to compensate the size difference\n",
        "    compared to the retinal image\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    NCC: array of int\n",
        "      Normalized Cross-Correlation map\n",
        "    h: int\n",
        "      height of source image\n",
        "    w: int\n",
        "      width of source image\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    zeropadded_ncc: array of int\n",
        "      zero padded NCC to the size of h and w\n",
        "  '''   \n",
        "  ver = (h - NCC.shape[0])/2\n",
        "  hor = (w - NCC.shape[1])/2\n",
        "  top = math.floor(ver)\n",
        "  bottom = math.ceil(ver)\n",
        "  left =  math.floor(hor)\n",
        "  right = math.ceil(hor)\n",
        "  value = 0\n",
        "  borderType = cv2.BORDER_CONSTANT\n",
        "  zeropadded_NCC = cv2.copyMakeBorder(NCC, top, bottom, left, right, borderType, value)\n",
        "  return zeropadded_NCC"
      ],
      "metadata": {
        "id": "7MthK_iV1q3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_template_matching(claheRetinalImg, template, mask):\n",
        "  '''\n",
        "    This is a function for OD template matching. This will yields Normalized\n",
        "    Correlation Coefficient (NCC) of R, G, and B channel. \n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    claheRetinalImg: array of int\n",
        "      RGB retinal image that had been CLAHE-ed\n",
        "    template: array of int\n",
        "      OD template image\n",
        "    mask: array of int\n",
        "      Mask for masking out the non-retinal area\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    NCC_maps: array of int\n",
        "      NCC image of R, G, and B channel\n",
        "  '''\n",
        "\n",
        "  h, w = claheRetinalImg[0].shape[:2]\n",
        "  NCC_maps = []\n",
        "  for i, clahe_image in enumerate(claheRetinalImg):\n",
        "    # checking clahe image isn't zeros \n",
        "    if len(np.unique(clahe_image)) > 0: \n",
        "      NCC = cv2.matchTemplate(clahe_image, template[i], cv2.TM_CCOEFF_NORMED)\n",
        "      NCC = NCC + abs(np.min(NCC))\n",
        "      NCC = padding(NCC, h, w)\n",
        "      NCC = NCC * mask\n",
        "\n",
        "    NCC_maps.append(NCC)\n",
        "  \n",
        "  return NCC_maps"
      ],
      "metadata": {
        "id": "ha85yZcm1skx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUsV36FZpS-j"
      },
      "outputs": [],
      "source": [
        "def OD_Localization(src, template_images, used_channels='rgb',\n",
        "                  bright_on=True, test_on=False, \n",
        "                  r_coeff=1, g_coeff=1, b_coeff=1, br_coeff=1):\n",
        "  '''\n",
        "    Localizes OD by looking for the estimated disc center\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    src: array of int\n",
        "      retinal images (RGB)\n",
        "    template_images: array of int\n",
        "      Optic Disc template images of R, G, B channles\n",
        "    used_channels: string\n",
        "      defining the used NCC channels for localization\n",
        "      must contain r, g, or b\n",
        "    NCC_on: boolean\n",
        "      Use NCC map for localization\n",
        "    bright_on: boolean\n",
        "      Use brightness map for localization\n",
        "    r_coeff: float\n",
        "      coefficient of red_NCC map\n",
        "      value between 0 to 1\n",
        "    g_coeff: float\n",
        "      coefficient of green_NCC map \n",
        "      value between 0 to 1\n",
        "    b_coeff: float\n",
        "      coefficient of blue_NCC map \n",
        "      value between 0 to 1\n",
        "    br_coeff: float\n",
        "      coefficient of brightness map \n",
        "      value between 0 to 1\n",
        "\n",
        "    Return\n",
        "    ----------\n",
        "    disk_center: tuple of int (x, y)\n",
        "      Optic Disc Center\n",
        "    all_maps: array of int\n",
        "      list of created maps for localization, returned only if test_on is True.\n",
        "  '''\n",
        "\n",
        "    \n",
        "  h, w = src.shape[:2]\n",
        "\n",
        "  # Implement CLAHE to the input image \n",
        "  clahe = cv2.createCLAHE(clipLimit =2.0, tileGridSize=(8,8))\n",
        "  cl_img = clahe.apply(src[:, :, 1])\n",
        "  \n",
        "  zeros = np.zeros([h, w], np.uint8)\n",
        "  img = [zeros, zeros, zeros]\n",
        "  \n",
        "  # Apply CLAHE to each of image channel \n",
        "  for channel in used_channels:\n",
        "    if channel == 'r':\n",
        "      img[0] = clahe.apply(src[:, :, 0])\n",
        "    elif channel == 'g':\n",
        "      img[1] = clahe.apply(src[:, :, 1])\n",
        "    elif channel == 'b':\n",
        "      image = clahe.apply(src[:, :, 2])\n",
        "      img[2] = image\n",
        "    \n",
        "  # Mask Out outside retinal image\n",
        "  blurred = cv2.GaussianBlur(cl_img, (7, 7), 0)\n",
        "  (T, mask) = cv2.threshold(blurred, 10 , 255, cv2.THRESH_BINARY)\n",
        "  mask = mask/255\n",
        "\n",
        "  # Extract the NCC maps\n",
        "  red_NCC, green_NCC, blue_NCC = image_template_matching(img, template_images, mask)\n",
        "\n",
        "  # Extract superpixel map\n",
        "  if bright_on:\n",
        "    brightness_map = extract_BR_map(src, mask)\n",
        "  else:\n",
        "    brightness_map = zeros\n",
        "\n",
        "  # Combining localization maps \n",
        "  combined_map = red_NCC * r_coeff + green_NCC*g_coeff + blue_NCC*b_coeff + brightness_map*br_coeff\n",
        "  all_maps = [combined_map, red_NCC, green_NCC, blue_NCC, brightness_map]\n",
        "  \n",
        "  # Extracting maximum value of NCC\n",
        "  y, x = list(zip(*np.where(combined_map==np.max(combined_map))))[0]\n",
        "  disk_center = (x, y)\n",
        "\n",
        "  # Return all maps for testing the algorithm only\n",
        "  if test_on:\n",
        "    return disk_center, all_maps \n",
        "  elif not test_on:\n",
        "    return disk_center"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2QAXd3aq7iy"
      },
      "outputs": [],
      "source": [
        "def ekstrakROI(centroid, s, img):\n",
        "  '''\n",
        "    crop the region of interest based on OD's estimated center \n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    centeroid : tuple of int (x, y)\n",
        "      estimated center of OD\n",
        "    s: float\n",
        "      size of ROI compared to the whole image\n",
        "      value between 0 - 1\n",
        "    img: array of int\n",
        "      source image\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    ROI: array of int\n",
        "      region of interest\n",
        "    koordinat: tupple (y0, y1, x0, x1)\n",
        "      coordinates value of ROI trim\n",
        "  '''\n",
        "\n",
        "  h, w = img.shape[:2]\n",
        " \n",
        "  y0, y1, x0, x1 = rectfromcenter(centroid, s, h, w)\n",
        "\n",
        "  #cropping ROI from source image\n",
        "  ROI = img[y0:y1, x0:x1]\n",
        "  koordinat = (y0, y1, x0, x1)\n",
        "\n",
        "  return ROI, koordinat"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rectfromcenter(center, s, h, w):\n",
        "  '''\n",
        "    calculate x and y value of a rectangle based of a coordinate\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    center : tuple of int (x, y)\n",
        "      coordinate value of rectangle's center\n",
        "    s: float\n",
        "      size of ROI compared to the whole image\n",
        "      value between 0 - 1\n",
        "    h: int\n",
        "      image height\n",
        "    w: int\n",
        "      image width\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    y0: int\n",
        "      the bottommost point of the rectangle\n",
        "    y1: int\n",
        "      the topmost point of the rectangle\n",
        "    x0: int\n",
        "      the leftmost point of the rectangle\n",
        "    x1: int\n",
        "      the righttmost point of the rectangle\n",
        "  '''\n",
        "  x, y = center\n",
        "  x0 = math.floor(x - 0.5*s)\n",
        "  x1 = math.floor(x + 0.5*s)\n",
        "  y0 = math.floor(y - 0.5*s)\n",
        "  y1 = math.floor(y + 0.5*s)\n",
        "\n",
        "  if (x0 < 0):\n",
        "    x1 = x1 + (-x0)\n",
        "    x0 = 0\n",
        "\n",
        "  elif (x1 > w-1):\n",
        "    x0 = x0 - (x1-(w-1))\n",
        "    x1 = w-1\n",
        "\n",
        "  if (y0 < 0):\n",
        "    y1 = y1 + (-y0)\n",
        "    y0 = 0\n",
        "\n",
        "  elif (y1 > h-1):\n",
        "    y0 = y0 - (y1-(h-1))\n",
        "    y1 = (h-1)\n",
        "\n",
        "  return y0, y1, x0, x1"
      ],
      "metadata": {
        "id": "IdY6Y3rT1wBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Segmentation Functions"
      ],
      "metadata": {
        "id": "SWHfopJbNL_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ellips_fittingOD(mask):\n",
        "  '''\n",
        "    Fitting the predicted area of OD into an an ellipse with circle\n",
        "    hough transform\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    mask: array of int\n",
        "      OD prediction mask\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    ellips: array of int\n",
        "      fitted OD mask\n",
        "    center: tuple of int (x, y)\n",
        "      coordinate values of ellipse\n",
        "    d: float\n",
        "      major axis of the ellipse\n",
        "    angle: float\n",
        "      angle of major axis\n",
        "  ''' \n",
        "  mask = mask.squeeze()\n",
        "\n",
        "  cnts, _= cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  cnts = sorted(cnts, key=cv2.contourArea, reverse=True)\n",
        "  elips = np.zeros((mask.shape[0], mask.shape[1]),np.uint8)\n",
        "  if len(cnts)>0:\n",
        "  # Ellipse fitting\n",
        "    ellipse = cv2.fitEllipse(cnts[0])\n",
        "    center, d, angle = ellipse\n",
        "    elips = cv2.ellipse(elips, ellipse, 255, cv2.FILLED)\n",
        "  else:\n",
        "    elips = mask\n",
        "    center = (0, 0)\n",
        "    d = (0, 0)\n",
        "    angle = 0\n",
        "  \n",
        "  ellips = np.expand_dims(elips, axis=-1)\n",
        "  ellips = np.array(elips)\n",
        "  ellips = elips.squeeze()\n",
        "  return ellips, center, d, angle"
      ],
      "metadata": {
        "id": "siyNk_SnP4C6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNW6zpBsu4u_"
      },
      "outputs": [],
      "source": [
        "def check_hier(mask):\n",
        "  '''\n",
        "    Calculate how many blobs with more than five\n",
        "    data point detected\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    mask: array of int\n",
        "      OC prediction mask\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    hier: int\n",
        "      number of blobs found\n",
        "  ''' \n",
        "  mask = mask.squeeze()\n",
        "  cnts, _= cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  hier = 0\n",
        "  for cnt in cnts:\n",
        "    if len(cnt) > 5:\n",
        "      hier += 1\n",
        "  return hier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Hv36Su_sO2P"
      },
      "outputs": [],
      "source": [
        "def ellips_fittingOC(mask, hier):\n",
        "  '''\n",
        "    Fitting the predicted area of OC into an an ellipse with circle\n",
        "    hough transform\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    mask: array of int\n",
        "      OC prediction mask\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    ellipsfitted: array of int\n",
        "      fitted OC mask\n",
        "  ''' \n",
        "  \n",
        "  mask = mask.squeeze()\n",
        "  # Select largest contour\n",
        "  cnts, _= cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  cnts = sorted(cnts, key=cv2.contourArea, reverse=True)\n",
        "  elips = np.zeros((mask.shape[0], mask.shape[1]),np.uint8)\n",
        "  if len(cnts)>0:\n",
        "  # Ellipse fitting\n",
        "    if hier > (len(cnts)-1):\n",
        "      hier = len(cnts) - 1\n",
        "    ellipse = cv2.fitEllipse(cnts[hier])\n",
        "    elips = cv2.ellipse(elips, ellipse, 255, cv2.FILLED)\n",
        "  else:\n",
        "    elips = mask\n",
        "\n",
        "  ellips = np.expand_dims(elips, axis=-1)\n",
        "  ellips = np.array(elips)\n",
        "  ellips = elips.squeeze()\n",
        "  return ellips"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ellipse_fitting(OD, OC):\n",
        "  '''\n",
        "    Driver function for ellipse fitting\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    OD_bin: array of int\n",
        "      OD prediction mask\n",
        "    OC_bin: array of int\n",
        "      OC prediction mask\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    OD_fit: array of int\n",
        "      fitted OD mask\n",
        "    OC_fit: array of int\n",
        "      fitted OC mask\n",
        "  '''\n",
        "  OD_fitted = []\n",
        "  OC_fitted = []\n",
        "  for i in range(len(OD)):\n",
        "    OD_bin = OD[i]\n",
        "    OC_bin = OC[i]\n",
        "    OD_fit, _, _, _ = ellips_fittingOD(OD_bin)\n",
        "    hier = 0\n",
        "    hier_max = check_hier(OC_bin)\n",
        "    if hier_max > 0:\n",
        "      OC_fit = ellips_fittingOC(OC_bin, 0)\n",
        "      check = np.sum(OC_fit[OD_fit == 255])/ np.sum(OC_fit[OC_fit == 255])\n",
        "      hier += 1\n",
        "\n",
        "      while (check < 0.3) and hier < (hier_max):\n",
        "        OC_fit = ellips_fittingOC(OC_bin, hier)\n",
        "        check = np.sum(OC_fit[OD_fit == 255])/ np.sum(OC_fit[OC_fit == 255])\n",
        "        hier += 1\n",
        "        if hier > hier_max:\n",
        "          break\n",
        "    else:\n",
        "      OC_fit = OC_bin.squeeze()*255\n",
        "    \n",
        "    OD_fitted.append(OD_fit)\n",
        "    OC_fitted.append(OC_fit)\n",
        "  \n",
        "  OD_fitted = np.array(OD_fitted)\n",
        "  OC_fitted = np.array(OC_fitted)\n",
        "\n",
        "  return OD_fitted, OC_fitted"
      ],
      "metadata": {
        "id": "5bZ_vCXIwx-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Extractions Functions\n",
        "\n"
      ],
      "metadata": {
        "id": "csted7p5Xfuw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hyevm117fsWu"
      },
      "outputs": [],
      "source": [
        "def CDRcalc(OD_feat, OC_feat):\n",
        "  '''\n",
        "    Calculate cup to disc ratio based on extracted features\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    OD_feat: tuple of float\n",
        "      features of optic disc\n",
        "      (height, length, area)\n",
        "    OC_feat: tuple of float\n",
        "      features of optic cup\n",
        "      (height, length, area)\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    VCDR: float\n",
        "      Vertical cup-to-disc ratio\n",
        "    HCDR: float\n",
        "      Horizontal cup-to-disc ratio\n",
        "    ACDR: float\n",
        "      Area cup-to-disc ratio\n",
        "  '''\n",
        "  VCDR = float(OC_feat[0]) / float(OD_feat[0]) # vertical CDR\n",
        "  HCDR = float(OC_feat[1]) / float(OD_feat[1]) # Horizontal CDR\n",
        "  ACDR = float(OC_feat[2]) / float(OD_feat[2]) # Area CDR\n",
        "\n",
        "  return VCDR, HCDR, ACDR"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getFeature(mask):\n",
        "  '''\n",
        "    Extract features such as length, height, and area from\n",
        "    OD or OC mask\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    mask: array of int\n",
        "      Segmentation mask of OD or OC\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    ver: float\n",
        "      Height of mask\n",
        "    hor: float\n",
        "      Length of mask\n",
        "    area: int\n",
        "      Area of mask\n",
        "  '''\n",
        "  cont, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
        "  cont = cv2.approxPolyDP(cont[0], 3, True)\n",
        "  _, _, hor, ver = cv2.boundingRect(cont)\n",
        "  area = np.sum(mask == 255)\n",
        "\n",
        "  return ver, hor, area"
      ],
      "metadata": {
        "id": "Tjmxt7VZrBaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getCenter(mask):\n",
        "  '''\n",
        "    Compute center of mask\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    mask: array of int\n",
        "      Segmentation mask of OD or OC\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    center: tuple of int\n",
        "      Mask's center\n",
        "      (x, y)\n",
        "  '''\n",
        "  M = cv2.moments(mask)\n",
        "  center = (int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"]))\n",
        "\n",
        "  return center"
      ],
      "metadata": {
        "id": "Rwg1NeN8rtUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getODAxes(mask):\n",
        "  '''\n",
        "    Driver function for feature extraction of OD\n",
        "    Compute its center, features, and angle of axis\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    mask: array of int\n",
        "      Segmentation mask of OD\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    center: tuple of int\n",
        "      Mask's center\n",
        "      (x, y)\n",
        "    feat: tuple of float\n",
        "      features of OD\n",
        "      (height, width, area)\n",
        "    angle: float\n",
        "      angle of tilt\n",
        "  '''\n",
        "  c_OD, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
        "  ellipse = cv2.fitEllipse(c_OD[0])\n",
        "  center, (hor, ver), angle = ellipse\n",
        "  area = np.sum(mask == 255)\n",
        "  \n",
        "  if (angle > 45) and (angle <= 135):\n",
        "    angle -= 90\n",
        "    temp = hor\n",
        "    hor = ver\n",
        "    ver = temp\n",
        "\n",
        "  elif (angle > 135) and (angle <= 180):\n",
        "    angle -= 180\n",
        "\n",
        "  return center, (ver, hor, area), angle"
      ],
      "metadata": {
        "id": "l1eyIZMQufHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getOCAxes(mask, angle):\n",
        "  '''\n",
        "    Driver function for feature extraction of OC\n",
        "    Compute its center, features, and angle of axis\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    mask: array of int\n",
        "      Segmentation mask of OC\n",
        "    angle: float\n",
        "      tilt of OD\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    center: tuple of int\n",
        "      Mask's center\n",
        "      (x, y)\n",
        "    feat: tuple of float\n",
        "      features of OC\n",
        "      (height, width, area)\n",
        "    angle: float\n",
        "      angle of tilt\n",
        "  '''\n",
        "  center = getCenter(mask)\n",
        "  rot_mat = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "  mask = cv2.warpAffine(mask, rot_mat, mask.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
        "  feat = getFeature(mask)\n",
        "\n",
        "  return center, feat, angle"
      ],
      "metadata": {
        "id": "kvdptQoKv9nI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Driver Functions"
      ],
      "metadata": {
        "id": "DKpZUcq-4C6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def uploadImage():\n",
        "  uploaded = files.upload()\n",
        "  src_image = []\n",
        "  filenames = list(uploaded.keys())\n",
        "  for image_path in filenames:\n",
        "    img = cv2.imread(image_path, 1) # reading image retina\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Konversi warna BGR ke RGB\n",
        "    src_image.append(img)\n",
        "  return src_image, filenames"
      ],
      "metadata": {
        "id": "5c7NX4Bu3AIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def localization(src_image, image_templates):\n",
        "  r_coeff, g_coeff,b_coeff, br_coeff = 1, 0.2, 0, 0.8\n",
        "  used_channels = 'rg'\n",
        "  clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "  \n",
        "  loc_imgs = []\n",
        "  for img in src_image:\n",
        "    disc_center, all_maps = OD_Localization(img, image_templates,\n",
        "                                            used_channels=used_channels, \n",
        "                                            bright_on=True, \n",
        "                                            test_on=True, \n",
        "                                            r_coeff=r_coeff, \n",
        "                                            g_coeff=g_coeff, \n",
        "                                            b_coeff=b_coeff,\n",
        "                                            br_coeff=br_coeff)\n",
        "    img = clahe.apply(img[:,:,1])\n",
        "    shape = (img.shape[1], img.shape[0])\n",
        "    img,_ = ekstrakROI(disc_center, (0.3*shape[0]), img)\n",
        "    img = resize(img, (550, 550, 1), mode = 'constant', preserve_range = True)\n",
        "    loc_imgs.append(img)\n",
        "  \n",
        "  loc_imgs = np.array(loc_imgs)\n",
        "  return loc_imgs"
      ],
      "metadata": {
        "id": "_TuJ9skA-Fzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def segmentation(img):\n",
        "  img = resize(img, (len(img), 256, 256, 1),mode = 'constant',\n",
        "               preserve_range = True)/255.0\n",
        "  img = np.array(img)\n",
        "  # Predict \n",
        "  OD = model_OD.predict(img, verbose=0)\n",
        "  OC = model_OC.predict(img, verbose=0)\n",
        "  # binarize\n",
        "  OD_bin = (OD > 0.5).astype(np.uint8)\n",
        "  OC_bin = (OC > 0.5).astype(np.uint8)\n",
        "  \n",
        "  return ellipse_fitting(OD_bin, OC_bin)"
      ],
      "metadata": {
        "id": "ca1U1azh93iC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def featureExtraction(OD, OC):\n",
        "  CDR = []\n",
        "  for i in range(len(OD)):\n",
        "    _, featOD, angle = getODAxes(OD[i])\n",
        "    _, featOC, _ = getOCAxes(OC[i], angle)\n",
        "    CDR.append(CDRcalc(featOD, featOC))\n",
        "  \n",
        "  CDR = np.array(CDR)\n",
        "  return CDR"
      ],
      "metadata": {
        "id": "01T4z11F94-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def glaucomaClassification(CDR, filenames):\n",
        "  preds = model2a_axes.predict([(i[0], i[2]) for i in CDR])\n",
        "  classes = ['Normal', 'Glaucoma']\n",
        "  preds = [classes[x] for x in preds]\n",
        "  print('%-3s | %-18s | %-10s' % (\"No.\", \"File Name\", \"Prediction\"))\n",
        "  print('%-3s | %-18s | %-10s' % (\"---\", \"------------------\", \"----------\"))\n",
        "  for i in range(len(preds)):\n",
        "    print('%-3i | %-18s | %-10s' % (i + 1, filenames[i], preds[i]))"
      ],
      "metadata": {
        "id": "IH_3zWoPYB_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display analysis functions\n",
        "'''\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "def showImg(img):\n",
        "  if img.shape[2] == 1:\n",
        "    plt.imshow(img, cmap='gray')\n",
        "  else:\n",
        "    plt.imshow(img)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  \n",
        "  plt.show()\n",
        "\n",
        "def showSegmentation(ROI, OD, OC):\n",
        "  plt.imshow(ROI, cmap='gray')\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.contour(OD, colors='royalblue')\n",
        "  plt.contour(OC, colors='darkorange')\n",
        "  plt.show()\n",
        "\n",
        "def showFeatures(ROI, OD, OC):\n",
        "  centerOD, featOD, angle = getODAxes(OD)\n",
        "  centerOC, featOC, _ = getOCAxes(OC, angle)\n",
        "  V, H, A = CDRcalc(featOD, featOC)\n",
        "\n",
        "  boxOD = cv2.boxPoints((centerOD, tuple((featOD[1], featOD[0])), angle))\n",
        "  boxOC = cv2.boxPoints((centerOC, tuple((featOC[1], featOC[0])), angle))\n",
        "\n",
        "  plt.imshow(ROI, cmap='gray')\n",
        "  plt.text(10, 80,\n",
        "           'VCDR: {:.3f}\\nHCDR: {:.3f}\\nACDR: {:.3f}'.format(V, H, A),\n",
        "           size='small', color='w')\n",
        "  plt.contour(OD, colors='royalblue')\n",
        "  plt.contour(OC, colors='darkorange')\n",
        "  plt.gca().add_patch(Rectangle((boxOD[1]), featOD[1], featOD[0],\n",
        "                                angle=angle, edgecolor='red',\n",
        "                                facecolor='none', lw=2))\n",
        "  plt.gca().add_patch(Rectangle((boxOC[1]), featOC[1], featOC[0],\n",
        "                                angle=angle, edgecolor='red',\n",
        "                                facecolor='none', lw=2))\n",
        "  plt.plot(centerOC[0], centerOC[1], 'o', color='blue')\n",
        "  plt.grid(False)\n",
        "'''"
      ],
      "metadata": {
        "id": "ObSY2pgwTBfF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "13a75785-2937-4786-8596-32020c02a414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfrom matplotlib import pyplot as plt\\nfrom matplotlib.patches import Rectangle\\ndef showImg(img):\\n  if img.shape[2] == 1:\\n    plt.imshow(img, cmap='gray')\\n  else:\\n    plt.imshow(img)\\n  plt.xticks([])\\n  plt.yticks([])\\n  \\n  plt.show()\\n\\ndef showSegmentation(ROI, OD, OC):\\n  plt.imshow(ROI, cmap='gray')\\n  plt.xticks([])\\n  plt.yticks([])\\n  plt.contour(OD, colors='royalblue')\\n  plt.contour(OC, colors='darkorange')\\n  plt.show()\\n\\ndef showFeatures(ROI, OD, OC):\\n  centerOD, featOD, angle = getODAxes(OD)\\n  centerOC, featOC, _ = getOCAxes(OC, angle)\\n  V, H, A = CDRcalc(featOD, featOC)\\n\\n  boxOD = cv2.boxPoints((centerOD, tuple((featOD[1], featOD[0])), angle))\\n  boxOC = cv2.boxPoints((centerOC, tuple((featOC[1], featOC[0])), angle))\\n\\n  plt.imshow(ROI, cmap='gray')\\n  plt.text(10, 80,\\n           'VCDR: {:.3f}\\nHCDR: {:.3f}\\nACDR: {:.3f}'.format(V, H, A),\\n           size='small', color='w')\\n  plt.contour(OD, colors='royalblue')\\n  plt.contour(OC, colors='darkorange')\\n  plt.gca().add_patch(Rectangle((boxOD[1]), featOD[1], featOD[0],\\n                                angle=angle, edgecolor='red',\\n                                facecolor='none', lw=2))\\n  plt.gca().add_patch(Rectangle((boxOC[1]), featOC[1], featOC[0],\\n                                angle=angle, edgecolor='red',\\n                                facecolor='none', lw=2))\\n  plt.plot(centerOC[0], centerOC[1], 'o', color='blue')\\n  plt.grid(False)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Glaucoma Detection"
      ],
      "metadata": {
        "id": "YkCSKKsmyfJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload fundus image\n",
        "src_img, filenames = uploadImage()"
      ],
      "metadata": {
        "id": "HZI4md2SkF7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run localization\n",
        "ROI_img = localization(src_img, image_templates)"
      ],
      "metadata": {
        "id": "DpRrpK1j5yOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Segmentation\n",
        "OD, OC = segmentation(ROI_img)"
      ],
      "metadata": {
        "id": "sipvmbYBLv5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run feature extraction\n",
        "CDR = featureExtraction(OD, OC)"
      ],
      "metadata": {
        "id": "q3bbi3Z7YL5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run glaucoma classification\n",
        "glaucomaClassification(CDR, filenames)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhC-PH88DaC_",
        "outputId": "2a52c351-a7f5-4a0c-d58c-359cc44190eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. | File Name          | Prediction\n",
            "--- | ------------------ | ----------\n",
            "1   | drishtiGS_010.png  | Glaucoma  \n",
            "2   | drishtiGS_092.png  | Normal    \n",
            "3   | n0294.jpg          | Normal    \n",
            "4   | n0317.jpg          | Normal    \n"
          ]
        }
      ]
    }
  ]
}